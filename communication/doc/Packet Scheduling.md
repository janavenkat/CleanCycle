## Introduction and background
As with all methods of data transfer, the speed at which we can send data varies with the signal strength, and in our case this is affected by many things. Signal strength can be weakened by antenna size, broadcast power, distance from the gateway, nearby obstacles such as trees and buildings, the type of materials nearby, etc.  
For LoRaWAN there are various bands and bandwidths that we can use. Use of these bands is region-based and dictated by local government, and in Europe we are limited to using at maximum bandwidth of 250kHz at a frequency of 868MHz. However, this is only in ideal circumstances which are not realistically achievable, particularly when the device is in motion. Because of this, we will focus our discussion solely on 125kHz transmission.  
In addition to bandwidth, there is also the Spreading Factor (SF) of the transmission. Lower SF values mean we can transmit the same data in a shorter period of time but also mean that the message is more prone to noise. This means when the signal strength is weaker we need to use a higher SF value in order for it to be more likely that the message gets to the gateway intact.  
SF values range from SF7 (fastest) to SF12(slowest). In general it is best to use the lowest number possible, but if the signal strength is too weak the message may not get to the gateway.  
Since we want to maximise the amount of data we can transfer, it would be best for us to only ever transfer at SF7. However, this would not be feasible as it would mean that almost all of the data collected in rural areas would never reach a gateway and hence we would lose a large amount of pollution data. Transmitting at higher SF values would guarantee that the majority of messages are received, but transmission would take much longer and so we would quickly use up the fixed amount of airtime that we are allowed.  
This means we need to implement a system where we buffer the data so that we can send it all at once when we get a window of high signal strength.  



## The Buffer
We can use some resources on the chip in order to buffer the data while we find somewhere with better signal strength. The buffered data can be held in memory since we are not expecting to have very large buffers. The microcontroller has 20KB of RAM, so to be conservative we can limit ourselves to 4KB of RAM for storing the buffered data. We can continue writing the complete raw data to the SD card, but since we are only transferring a small part of it via the wireless connection, we can store the buffered data in the encoded format that is discussed in the other document. It may also be beneficial to periodically backup the current buffer to the SD card, since the chip could be switched off at any point, meaning data stored in RAM could be lost. This SD card backup of the buffer should also be updated each time we transmit or write data to the on-RAM buffer. This SD card backup would then be read on startup and used as the start of the backup for that session.  
We can store a maximum of 80 encoded messages in the 4KB of RAM we are allocating to the buffer. This corresponds to 480 datapoints, which means around 24 minutes of data collection. This is a long enough window of time that it is reasonable to expect some time periods where we have good enough signal strength to be able to send and clear part of the buffer.


## Buffer data prioritisation
One simple but effective way of implementing prioritisation of which parts of the buffer should be sent is to just use a First-In First-Out (FIFO) queue. This means that the oldest data is the data that will be sent first, and data that has been in the buffer for a long time is likely to be data about more rural areas, since if it wasn’t sent then the signal strength was weak when we tried to send it. In addition, locations where the signal strength is good enough to begin data transfer are likely to be in busy built-up areas, so the data that has been most recently gathered is likely to be lower-priority data since it’s likely someone will go past that location in the future and gather data about it.  
This method of prioritising data has very low overhead both for storing the data structure required and for finding out which data should be sent next, meaning it is suitable for low-power devices.

Another way of implementing prioritisation would be using a priority queue. We could use the signal strength as the key for the priority queue, with lower signal strengths meaning higher priority.  
This has the advantage of always giving us the data which was gathered in lowest signal strength regions, meaning we are likely to be sending data about a previously unseen location, but requires much more overhead. We would need to store all the signal strengths with their respective data packet and we would also need to spend some time on the CPU both when inserting data into and removing data from the priority queue. This extra CPU utilisation would also lead to more power draw, meaning the batteries would not last as long.


## Deciding when to send the data
While buffering, the system should periodically check the current signal strength and, if it allows for SF7 transmission, we should transmit as much data as possible in order to maximise the data that can be sent. However, if the signal strength does not allow for SF7 transmissions, then we need to make a choice.

In order to choose whether we should transmit or not, we need to know whether we can afford to wait to transmit, how beneficial it would be to continue buffering the data, and how likely it is that the signal strength is going to improve.  
One situation in which we can’t afford to wait is if the buffer is full. If we have a full buffer, we are forced to either transmit the data at the current rate or to not transmit those data points at all and just write them to the SD card. However, we should start considering transmitting much earlier than when the buffer becomes full, as waiting longer could lead to the signal strength decreasing more, putting us in an even worse position.

One way of implementing this decision making would be to just check the recent trend of signal strength for the last few datapoints. If it seems to be increasing, then it would be better to wait since we expect it to increase more. If it seems to be decreasing, then sending off some data now could be the better choice since it’s expected to decrease more. This system would require fairly low overhead and would be simple to implement, but would not lead to the most efficient data transfer as it doesn’t transfer data at the most efficient times.

A more complex way to make a decision would be to use a probabilistic model. We would keep a history of previous and current signal strength, as well as keeping track of how much empty buffer space there is. We can then generate a model which tells us how good it would be to keep buffering the data by giving the model all of the above data. If the response from the model is below a certain threshold, then we should send some data, otherwise we should keep buffering the data until the value crosses the threshold.

This model has the advantage that it would be much better at deciding if it is a good time to send the data or not since it is not as simple as the previous example, and takes into account how full or empty the buffer is. We can also train the model using data in order to improve its performance.  
There are, however, some disadvantages to using this approach. One of these is that it would require extra computation on the microprocessor every time we want to check if data should be sent. This means extra power draw, so the batteries would drain faster. This could be mitigated by performing the computation less often, but this could lead to a window of good signal strength being missed.
Another disadvantage is that we need to set up the parameters for the model. Since there currently no geographical data about LoRaWAN signal strength, we would need to infer this data from the location of gateways. However, this would not be very accurate since it doesn’t take into account the surroundings of the gateways and the materials that nearby buildings are made from, which could have a significant impact on the accuracy of the actual values.

One further method of making this decision is to take inspiration from the previous example but try to offload the computation to the server. We could collect signal strength data on the device and put it in the free bits at the end of each encoded wireless packet. We could then use all the signal data on the server to calculate the areas where it is best to transmit from the device. This would then need to be passed to the device, which creates a further problem: we are limited to only 10 downlink (server -> device) messages per day. This means we can’t constantly tell the device whether it should transmit or not.  
In order to devise a way of overcoming this, further investigation would be required. Initial thoughts are that we could try to send the device information about where some good nearby areas to transmit are, but we would have to find out how much of this information we could send to the device and how much RAM we can allocate to it. If this were to indeed prove infeasible, another option could be to write geographical signal strength data to the device when it is programmed. This has further issues, such as the inability to update this data and the fact that we can only upload a certain amount of data, meaning the data we upload would only cover a fixed region. This could mean that a device programmed using data from Cambridge may not be able to use this approach in Cardiff, so we would still need to implement the previous method as a fallback.
